{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kernel Density Estimation for Flow Cytometry Data  \n",
    "\n",
    "**Using kernel density estimation (KDE) to analyze multivariate flow cytometry data.**\n",
    "\n",
    "By Jihyun Park (`jihyunp@ics.uci.edu`) and Padhraic Smyth (`smyth@ics.uci.edu`)<br/>\n",
    "Department of Computer Science, University of California, Irvine\n",
    "\n",
    "Presented as part of the UCI BigDIPA Lab\n",
    "\n",
    "September 2017"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outline\n",
    "-------------------------\n",
    "Kernel density estimation (KDE) is a non-parametric way to estimate a probability density function.\n",
    "It uses a finite sample of data to make inferences about the underlying probability density function that generated the data.\n",
    "\n",
    "In this portion of the lab we will use KDE techniques to analyze multidimensional data obtained via flow cytometry from human subjects."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requirements\n",
    "--------------------------------\n",
    "- Familiarity with the main KDE python notebook for the BigDIPA course.\n",
    "- Basic knowledge of probability.\n",
    "- Familiarity with programming and nD array computing (e.g. working with matrices in Matlab or numpy in python).\n",
    "- Python 3.5 or Python 2.7 with libraries : Jupyter (for ipython notebook), numpy, scipy, scikit-learn, matplotlib.\n",
    "- It is recommended to have the newest version of libraries installed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "----------------------------------\n",
    "- [Scikit-learn Density Estimation](http://scikit-learn.org/stable/modules/density.html) : Description and examples on density estimation including KDE.\n",
    "- [Scikit-learn KDE Package Documentation](http://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KernelDensity.html) : `KernelDensity` class documentation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Before We Start : Import Packages\n",
    "-----------------------------\n",
    "\n",
    "Import the necessary packages (you may have already imported them)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "matplotlib.style.use('classic')\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.neighbors import KernelDensity\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "# from sklearn.grid_search import GridSearchCV # if you have older version of sklearn\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you get an **`ImportError`** for **`model_selection`**, \n",
    "you can try importing **`GridSearchCV`** from **`sklearn.grid_search`** package.\n",
    "\n",
    "- `from sklearn.grid_search import GridSearchCV`\n",
    "\n",
    "or, update your **`scikit-learn`** using one of these commands below in **terminal window**.\n",
    "\n",
    "- `conda install scikit-learn` : If you installed python through anaconda\n",
    "- `pip install -U scikit-learn`\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Flow Cytometry Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# define the directory where the data is\n",
    "datapath = './spatial_data/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will import a standard flow-cytometry data set. \n",
    "\n",
    "Each row in the file corresponds to a single cell from a blood sample taken from a specific individual.\n",
    "\n",
    "There are 5 columns, each of which corresponds to a different *marker*. A marker is essentially a way to measure some physical or chemical property of a cell, e.g., its size. So we can think of the 5 markers as 5 different measurements for each cell.\n",
    "\n",
    "Below we will select dimensions 2 and 3 as the markers we will analyze. In a typical flow cytometry data analysis we would look at all dimensions (all columns), but since its easier to visualize data in 2 dimensions we will just focus on dimensions 2 and 3 here.\n",
    "\n",
    "As a sidenote, modern flow cytometry data sets are often much more complex than the single file we are analyzing here, e.g.,\n",
    "- there can be 10, 20, or more dimensions (markers)\n",
    "- there can be many different files corresponding to different time-points or tissues for the same individual, or multiple individuals\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Read in the flow-cytometry data matrix\n",
    "filename = datapath + \"flow_cytometry.csv\" \n",
    "FCdata = pd.read_csv(filename).as_matrix()\n",
    "print(FCdata.shape)\n",
    "\n",
    "# Extract columns 2 and 3 and store in Xdata  \n",
    "Xdata =  FCdata[:,2:4]\n",
    "print(Xdata.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART 1\n",
    "-------------------------------\n",
    "\n",
    "\n",
    "## 1. Plot the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we plot the data in the two dimensional space (marker 1 and marker 2) that we have selected to analyze. \n",
    "\n",
    "We see that there appears to be cluster structure in the data. We would expect that the KDEs (with an appropriate bandwidth selected) will show that there are at least 2 large modes in the data.\n",
    "\n",
    "Note that these modes or clusters correspond to different types of blood cells that are biologically-meaningful. There is significant interest in being able to automatically detect such clusters of cells (e.g., for biological discovery and for clinical cancer diagnosis)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(5,5))\n",
    "# Plot the data points\n",
    "ax.scatter(Xdata[:,0], Xdata[:,1], s=20, alpha=0.5, linewidth=0)\n",
    "ax.set_xlabel('Marker 2 (SS)')\n",
    "ax.set_ylabel('Marker 3 (FL1.LOG)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid arrays\n",
    "Before we plot the density, we will generate arrays for grids. This is because we want a density value for each grid location. We're going to generate 100 X 100 mesh grid. If you want to make the grid denser, change the number for **`ngrid`** in the below code to something larger.\n",
    "\n",
    "After generating the mesh grid, we're going to flatten the matrix to have (N x 2) shape so that it can be used as an input for other functions. <br\\> \n",
    "The variables **`X, Y, xy, `**and **`ngrid`**  will be used throughout the lab. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Generate Mesh Grid for Plotting (ngrid x ngrid matrix)\n",
    "\n",
    "# limits and grids for FC data\n",
    "lower_lim = -100\n",
    "upper_lim = 800\n",
    "\n",
    "ngrid = 200  # Because it'll take long (we have more data points)\n",
    "\n",
    "xgrid = np.linspace(lower_lim, upper_lim, ngrid)\n",
    "ygrid = np.linspace(lower_lim, upper_lim, ngrid)\n",
    "\n",
    "X, Y = np.meshgrid(xgrid, ygrid) # Now we have (ngrid x ngrid) matrix\n",
    "\n",
    "# ravel() function flattens (ngrid x ngrid) matrix -> (1 x ngrid**2) array\n",
    "xy = np.vstack([X.ravel(), Y.ravel()]).T\n",
    "\n",
    "# Print the shapes!\n",
    "print('Shape of X and Y: ' + str(X.shape))\n",
    "print('Shape of xy: ' + str(xy.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Define a wrapper function that runs KDE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now define a wrapper function that runs KDE and returns the evaluated density $\\hat{p}(x)=  \\frac{1}{N} \\sum_{i=1}^{N} K\\left(x - x_i; h \\right)$ in `(ngrid X ngrid)` matrix form. <br/>\n",
    "It is better to define a wrapper function since this will be used a lot!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def run_kde(Xdata, bandwidth, metric, kernel):\n",
    "    \"\"\" Construct a KernelDensity object, fit with the data points we generated, \n",
    "        and then return the evaluated density for the (ngrid X ngrid) mesh grid \"\"\"\n",
    "    # Construct a kernel density object\n",
    "    kde = KernelDensity(bandwidth=bandwidth, metric=metric, kernel=kernel)\n",
    "    kde.fit(Xdata)\n",
    "    # kde.score_samples() returns values in log scale\n",
    "    # xy is the flattened mesh grid that we defined earlier (used as global var.)\n",
    "    log_p_hat = kde.score_samples(xy)\n",
    "    phat = np.exp(log_p_hat)\n",
    "    phat = phat.reshape((ngrid, ngrid))\n",
    "    return phat\n",
    "\n",
    "print('Function run_kde() defined.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Plot the estimated density\n",
    "### 3.1 Manually selected bandwidth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Generate the estimated density using kernel density estimation\n",
    "selected_bw = 60\n",
    "phat = run_kde(Xdata, bandwidth=selected_bw, metric='euclidean', kernel='gaussian') \n",
    "\n",
    "fig, axs = plt.subplots(1,2,figsize=(11,5), sharex=True, sharey=True) \n",
    "ax = axs[0]\n",
    "levels = np.linspace(phat.min(), phat.max(), 20)\n",
    "im = ax.contourf(X, Y, phat, levels=levels, cmap='Blues')\n",
    "ax.set_xlabel('Marker 2 (SS)')\n",
    "ax.set_ylabel('Marker 3 (FL1.LOG)')\n",
    "ax.set_title('Density from KDE (BW=%.2f)' % selected_bw)\n",
    "\n",
    "ax = axs[1]\n",
    "ax.scatter(Xdata[:,0], Xdata[:,1], s=30, c='blue', alpha=0.5, linewidth=0)\n",
    "ax.set_xlim(lower_lim, upper_lim)\n",
    "ax.set_ylim(lower_lim, upper_lim)\n",
    "ax.set_xlabel('Marker 2 (SS)')\n",
    "ax.set_ylabel('Marker 3 (FL1.LOG)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Automated Bandwidth Selection\n",
    "\n",
    "Cross-validation can be used to select the bandwidth automatically. Cross-validation is a model validation technique for assessing how the results will generalize to an independent data set. In K-fold cross-validation, randomized data are splitted into K sets, and K-1 sets are used for estimating the density (train set) and 1 set is used for evaluation (validation set). We do this for K times, and score is calculated for the validation set at each run. The overall cross-validation score is the mean of the M scores. (More info: [Wikipedia: Cross-validation](https://en.wikipedia.org/wiki/Cross-validation_%28statistics%29))\n",
    "\n",
    "Scikit-learn has a nice package called **`GridSearchCV`** that does all the job for us! It uses **`score()`** function in the object to calculate the score. **`KernelDensity`** class has a function **`score(valX)`** that returns the total log probability of the validation data **`valX`** under the model. **`GridSearchCV`** will calculate the cross-validation score for each bandwidth value, and then return the bandwidth that gave the highest score. <br/>(Package info: [sklearn.model_selection.GridSearchCV](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html))\n",
    "\n",
    "We will use 5-fold cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "min_bw = 30\n",
    "max_bw = 80\n",
    "grid = GridSearchCV(KernelDensity(metric='euclidean', kernel='gaussian'),\n",
    "                    {'bandwidth': np.linspace(min_bw, max_bw, 20)}, cv=5) # 5-fold cross-validation\n",
    "grid.fit(Xdata)\n",
    "print(grid.best_params_)\n",
    "bw_cv = grid.best_params_['bandwidth'] # Bandwidth value saved in 'bw_cv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Generate the estimated density using kernel density estimation\n",
    "phat = run_kde(Xdata, bandwidth=bw_cv, metric='euclidean', kernel='gaussian') \n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(11,5), sharex=True, sharey=True) \n",
    "ax = axs[0]\n",
    "levels = np.linspace(phat.min(), phat.max(), 20)\n",
    "im = ax.contourf(X, Y, phat, levels=levels, cmap='Blues')\n",
    "ax.set_xlim(lower_lim, upper_lim)\n",
    "ax.set_ylim(lower_lim, upper_lim)\n",
    "ax.set_xlabel('Marker 2 (SS)')\n",
    "ax.set_ylabel('Marker 3 (FL1.LOG)')\n",
    "ax.set_title('Density from KDE (BW=%.2f)' % bw_cv)\n",
    "\n",
    "ax = axs[1]\n",
    "ax.scatter(Xdata[:,0], Xdata[:,1], s=25, c='blue', linewidth=0, alpha=0.6)\n",
    "ax.set_xlabel('Marker 2 (SS)')\n",
    "ax.set_ylabel('Marker 3 (FL1.LOG)')\n",
    "ax.set_title('Data')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# PART 2 \n",
    "--------------------\n",
    "\n",
    "\n",
    "## K-Means Clustering\n",
    "\n",
    "Since we could clearly see two clusters in the data, we will try one of the famous clustering algorithms called **K-means**. The KMeans algorithm clusters data by trying to separate samples in n groups of equal variance, minimizing the within-cluster sum-of-squares. This algorithm requires the number of clusters to be specified.\n",
    "\n",
    "We are going to use scikit-learn's K-means package (`sklearn.cluster.KMeans`).\n",
    "\n",
    "K-means description on Scikit-learn : [http://scikit-learn.org/stable/modules/clustering.html#k-means](http://scikit-learn.org/stable/modules/clustering.html#k-means)<br>\n",
    "K-means package documentation : [http://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html](http://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=2, max_iter=300, tol=0.0001)\n",
    "kmeans = kmeans.fit(Xdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "kmeans.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "group0_idx = np.where(kmeans.labels_==0)[0]\n",
    "group1_idx = np.where(kmeans.labels_==1)[0]\n",
    "\n",
    "Xdata0 = Xdata[group0_idx]\n",
    "Xdata1 = Xdata[group1_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(Xdata.shape)\n",
    "print(Xdata0.shape, Xdata1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "centers = kmeans.cluster_centers_\n",
    "print(centers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(5,5), sharex=True, sharey=True) \n",
    "ax.scatter(Xdata0[:,0], Xdata0[:,1], s=30, c='blue', alpha=0.5, linewidth=0, label='Group0')\n",
    "ax.scatter(Xdata1[:,0], Xdata1[:,1], s=30, c='red', alpha=0.5, linewidth=0, label='Group1')\n",
    "ax.scatter(centers[:,0], centers[:,1], s=30, c='black', label='Center')\n",
    "ax.set_xlabel('Marker 2 (SS)')\n",
    "ax.set_ylabel('Marker 3 (FL1.LOG)')\n",
    "ax.legend(loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:py35]",
   "language": "python",
   "name": "conda-env-py35-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
